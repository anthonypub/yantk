{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our training data, the XOR function. Note the first column, of all ones, will be to compute biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nonlin = 'sigmoid'\n",
    "X = np.array([(1, -1, -1),(1, -1, 1),(1, 1, -1),(1, 1, 1)])\n",
    "Y = np.array([(1, 0), (0, 1),(0, 1),(1, 0)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are our starting weight matrices. WHI contains the weights projecting from the input layer to the hidden layer, and WOH contains the weights projecting from the hidden layer to the output layer. Note that WHI contains a first \"phantom\" row of all zeros; this is a little hack to for the bias computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHI: \n",
      "[[ 0.         0.         0.       ]\n",
      " [-0.0130107  0.001805   0.0170633]\n",
      " [ 0.0420667  0.0069242  0.0421364]\n",
      " [-0.0082391 -0.0285141  0.0302499]]\n",
      "WOH: \n",
      "[[ 0.0338  0.0046 -0.0072 -0.0052]\n",
      " [ 0.0264  0.0123  0.0093 -0.0101]]\n"
     ]
    }
   ],
   "source": [
    "WHI = np.array([(0, 0, 0),(-0.0130107, 0.0018050, 0.0170633), (0.0420667, 0.0069242, 0.0421364),(-0.0082391, -0.0285141, 0.0302499)])\n",
    "WOH = np.array([(0.0338, 0.0046, -0.0072, -0.0052),(0.0264, 0.0123, 0.0093, -0.0101)])\n",
    "print(\"WHI: \")\n",
    "print(WHI)\n",
    "print(\"WOH: \")\n",
    "print(WOH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start on the forward pass. In each case we will multiply the projection matrix by the input, with training instances in the columns, then applying the nonlinearity. We handle the bias by creating one extra hidden unit and resetting it to \"1\" after the activations have been computed. This requires extra computation, but in a realistically sized net it would be a tiny waste. First we'll define the nonlinearity. For now we are using the sigmoid function, but we will allow the user to specify the nonlinearity so we can use other choices later.\n",
    "\n",
    "To allow for arbitrary numbers of layers we'll pass the weight vectors in as a list, and return a list of activations (which we'll need later for backprop)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the sigmoid to produce the first hidden output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.        , 1.        , 1.        , 1.        ],\n",
      "       [0.49203092, 0.5005619 , 0.49293322, 0.5014644 ],\n",
      "       [0.49825153, 0.51931012, 0.50171362, 0.52276607],\n",
      "       [0.4975063 , 0.51262854, 0.48325549, 0.49837418]])\n",
      " array([[0.50747167, 0.50742393, 0.507485  , 0.50743727],\n",
      "       [0.50801454, 0.50805154, 0.50806134, 0.50809833]])]\n",
      "Error: 2.000481886223878\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def scalar_rectifier(x):\n",
    "    if x > 0:\n",
    "        return x;\n",
    "    return x * .01\n",
    "\n",
    "def rectifier(x):\n",
    "    return np.vectorize(scalar_rectifier)(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "def forward(x, WEIGHTS, nl):\n",
    "    #note that we transpose x to put the training examples in columns here\n",
    "    inAct = np.transpose(x);\n",
    "    activations=[]\n",
    "    for i in range(0, len(WEIGHTS)):\n",
    "        W = WEIGHTS[i]\n",
    "        NET = np.dot(W, inAct)\n",
    "        if nl == 'sigmoid':\n",
    "            act = sigmoid(NET);\n",
    "        elif nl == 'tanh':\n",
    "            act = np.tanh(NET);\n",
    "        elif nl == 'relu':\n",
    "            act = rectifier(NET);\n",
    "        else:\n",
    "            raise Exception('unsupported nonlinearity')\n",
    "        if i != len(WEIGHTS) - 1:\n",
    "            act[0,:] = 1\n",
    "        activations = activations + [act]\n",
    "        inAct = act\n",
    "    return np.array(activations)\n",
    "\n",
    "def compute_error(A, Y):\n",
    "    last = len(A) - 1\n",
    "    err = Y - A[last]\n",
    "    sqerr = err * err;\n",
    "    return np.sum(sqerr)\n",
    "    \n",
    "\n",
    "WEIGHTS = [WHI, WOH]\n",
    "activations = forward(X, WEIGHTS, 'sigmoid')\n",
    "print(activations)\n",
    "err = compute_error(activations, np.transpose(Y))\n",
    "print(\"Error: \" + str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was the easy part. Now let's do the hard part (backprop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update 0\n",
      "[[-0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
      " [-8.32979012e-06 -4.60187589e-08 -1.05779515e-08]\n",
      " [-1.25158941e-06  4.45952367e-07  5.51442796e-08]\n",
      " [ 7.56907358e-06  3.44835058e-08 -1.35145547e-08]]\n",
      "update 1\n",
      "[[-0.0018632  -0.00092551 -0.00095132 -0.00092782]\n",
      " [-0.00201359 -0.00100027 -0.00102782 -0.00100253]]\n"
     ]
    }
   ],
   "source": [
    "def sigderiv(x):\n",
    "    return (x * (1-x))\n",
    "def tanhderiv(x):\n",
    "    return(1 - (x*x))\n",
    "def recderiv_scalar(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    return 0.01\n",
    "\n",
    "def recderiv(x):\n",
    "    return np.vectorize(recderiv_scalar)(x)\n",
    "\n",
    "#The derivative of the cost function with respect to the output,\n",
    "# dE / dO\n",
    "def CostDeriv(gold, predicted):\n",
    "    return -(gold - predicted)\n",
    "    \n",
    "    \n",
    "def nlderiv(x, nl):\n",
    "    if nl == 'sigmoid':\n",
    "        return sigderiv(x)\n",
    "    elif nl == 'tanh':\n",
    "        return tanhderiv(x)\n",
    "    elif nl == 'relu':\n",
    "        return recderiv(x)\n",
    "    else:\n",
    "        raise Exception('unsupported nonlin')\n",
    "#A = activatitions from all layers\n",
    "#Y = targets\n",
    "#nl = nonlinearity type\n",
    "#returns a list of update weights\n",
    "def backprop(X, A, Y, W, nl, rate):\n",
    "    #First compute the gradients\n",
    "    #This is the derivative of the nonlinearity function.\n",
    "    updates = []\n",
    "    nlgrad = np.ones((1))\n",
    "    out_idx = len(A) - 1\n",
    "    gradients = []\n",
    "    #derivative of output w.r.t. net (z)\n",
    "    nlgrad = nlderiv(A[out_idx], nl)\n",
    "    #derivative of error w.r.t. output\n",
    "    dedo = CostDeriv(np.transpose(Y), A[out_idx])\n",
    "    delta_k = nlgrad * dedo\n",
    "    gradients = [delta_k]\n",
    "    delta_prev = delta_k\n",
    "    for i in range(out_idx - 1, -1, -1):\n",
    "        #print(\"iter \" + str(i))\n",
    "        #Compute the weighted gradient from prev layer\n",
    "        wg = np.transpose(W[i + 1]).dot(delta_prev)\n",
    "        deriv = nlderiv(A[i], nl)\n",
    "        delta_new = deriv * wg\n",
    "        delta_prev = delta_new\n",
    "        gradients = [delta_new] + gradients\n",
    "    #Now compute the updates\n",
    "    #for g in gradients:\n",
    "        #print(\"gradient: \")\n",
    "        #print(g);\n",
    "    for i in range(0, out_idx + 1):\n",
    "        if i > 0:\n",
    "            upcurr = gradients[i].dot(np.transpose(A[i - 1]))\n",
    "        else:\n",
    "            upcurr = gradients[i].dot(X) \n",
    "       \n",
    "        upcurr = upcurr * -rate\n",
    "        updates = updates + [upcurr]\n",
    "    return updates\n",
    "    \n",
    "up = backprop(X, activations, Y, WEIGHTS, 'sigmoid', .25)\n",
    "for i in range(0, len(up)):\n",
    "    print(\"update \" + str(i))\n",
    "    print(up[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0\n",
      "[[0.50747167 0.50742393 0.507485   0.50743727]\n",
      " [0.50801454 0.50805154 0.50806134 0.50809833]]\n",
      "\n",
      "it 1\n",
      "[[0.50665828 0.50660005 0.50667389 0.50661567]\n",
      " [0.50713557 0.50716124 0.50718483 0.5072105 ]]\n",
      "\n",
      "it 2\n",
      "[[0.50593404 0.50586646 0.50595166 0.50588411]\n",
      " [0.50635291 0.5063685  0.50640436 0.50641994]]\n",
      "\n",
      "it 3\n",
      "[[0.50528918 0.50521329 0.50530861 0.50523274]\n",
      " [0.50565603 0.50566263 0.50570943 0.50571603]]\n",
      "\n",
      "it 4\n",
      "[[0.50471502 0.50463172 0.50473605 0.50465278]\n",
      " [0.50503555 0.50503415 0.50509068 0.50508928]]\n",
      "\n",
      "it 5\n",
      "[[0.50420381 0.50411392 0.50422627 0.50413641]\n",
      " [0.50448309 0.50447457 0.50453977 0.50453125]]\n",
      "\n",
      "it 6\n",
      "[[0.50374867 0.50365291 0.5037724  0.50367667]\n",
      " [0.50399122 0.50397635 0.50404927 0.50403441]]\n",
      "\n",
      "it 7\n",
      "[[0.50334344 0.50324246 0.50336831 0.50326735]\n",
      " [0.50355329 0.50353278 0.50361256 0.50359206]]\n",
      "\n",
      "it 8\n",
      "[[0.50298266 0.50287703 0.50300853 0.50290292]\n",
      " [0.50316339 0.50313785 0.50322375 0.50319822]]\n",
      "\n",
      "it 9\n",
      "[[0.50266146 0.50255168 0.50268822 0.50257847]\n",
      " [0.50281625 0.50278624 0.50287758 0.50284758]]\n",
      "\n",
      "it 10\n",
      "[[0.50237548 0.50226202 0.50240305 0.50228961]\n",
      " [0.50250719 0.5024732  0.50256939 0.5025354 ]]\n",
      "\n",
      "it 11\n",
      "[[0.50212088 0.50200413 0.50214916 0.50203244]\n",
      " [0.50223204 0.5021945  0.502295   0.50225747]]\n",
      "\n",
      "it 12\n",
      "[[0.50189421 0.50177454 0.50192312 0.50180348]\n",
      " [0.50198707 0.50194637 0.50205071 0.50201003]]\n",
      "\n",
      "it 13\n",
      "[[0.50169241 0.50157013 0.50172188 0.50159963]\n",
      " [0.50176897 0.50172546 0.50183322 0.50178973]]\n",
      "\n",
      "it 14\n",
      "[[0.50151274 0.50138815 0.50154271 0.50141815]\n",
      " [0.5015748  0.50152879 0.5016396  0.5015936 ]]\n",
      "\n",
      "it 15\n",
      "[[0.50135279 0.50122613 0.5013832  0.50125658]\n",
      " [0.50140193 0.50135369 0.50146721 0.50141899]]\n",
      "\n",
      "it 16\n",
      "[[0.50121038 0.50108189 0.50124119 0.50111274]\n",
      " [0.50124802 0.5011978  0.50131374 0.50126353]]\n",
      "\n",
      "it 17\n",
      "[[0.5010836  0.50095347 0.50111477 0.50098467]\n",
      " [0.501111   0.50105902 0.5011771  0.50112513]]\n",
      "\n",
      "it 18\n",
      "[[0.50097072 0.50083914 0.50100221 0.50087066]\n",
      " [0.50098902 0.50093546 0.50105545 0.50100191]]\n",
      "\n",
      "it 19\n",
      "[[0.50087024 0.50073736 0.500902   0.50076915]\n",
      " [0.50088041 0.50082546 0.50094715 0.50089221]]\n",
      "\n",
      "it 20\n",
      "[[0.50078077 0.50064674 0.50081278 0.50067879]\n",
      " [0.50078373 0.50072753 0.50085073 0.50079455]]\n",
      "\n",
      "it 21\n",
      "[[0.50070112 0.50056607 0.50073335 0.50059833]\n",
      " [0.50069765 0.50064034 0.50076489 0.5007076 ]]\n",
      "\n",
      "it 22\n",
      "[[0.50063021 0.50049424 0.50066264 0.50052671]\n",
      " [0.50062101 0.50056272 0.50068847 0.50063019]]\n",
      "\n",
      "it 23\n",
      "[[0.50056708 0.5004303  0.50059969 0.50046294]\n",
      " [0.50055278 0.50049361 0.50062043 0.50056127]]\n",
      "\n",
      "it 24\n",
      "[[0.50051088 0.50037337 0.50054364 0.50040616]\n",
      " [0.50049204 0.50043209 0.50055986 0.50049992]]\n",
      "\n",
      "it 25\n",
      "[[0.50046084 0.50032269 0.50049374 0.50035562]\n",
      " [0.50043796 0.50037731 0.50050593 0.5004453 ]]\n",
      "\n",
      "it 26\n",
      "[[0.50041629 0.50027757 0.50044932 0.50031062]\n",
      " [0.50038982 0.50032855 0.50045792 0.50039667]]\n",
      "\n",
      "it 27\n",
      "[[0.50037663 0.5002374  0.50040977 0.50027056]\n",
      " [0.50034695 0.50028513 0.50041517 0.50035337]]\n",
      "\n",
      "it 28\n",
      "[[0.50034133 0.50020163 0.50037456 0.5002349 ]\n",
      " [0.50030879 0.50024648 0.50037712 0.50031483]]\n",
      "\n",
      "it 29\n",
      "[[0.50030989 0.50016979 0.50034321 0.50020314]\n",
      " [0.50027482 0.50021207 0.50034324 0.50028051]]\n",
      "\n",
      "it 30\n",
      "[[0.50028191 0.50014145 0.5003153  0.50017487]\n",
      " [0.50024457 0.50018144 0.50031308 0.50024996]]\n",
      "\n",
      "it 31\n",
      "[[0.50025699 0.50011621 0.50029045 0.50014971]\n",
      " [0.50021764 0.50015416 0.50028623 0.50022276]]\n",
      "\n",
      "it 32\n",
      "[[0.50023481 0.50009374 0.50026833 0.5001273 ]\n",
      " [0.50019367 0.50012988 0.50026232 0.50019855]]\n",
      "\n",
      "it 33\n",
      "[[0.50021506 0.50007374 0.50024864 0.50010735]\n",
      " [0.50017233 0.50010827 0.50024103 0.50017699]]\n",
      "\n",
      "it 34\n",
      "[[0.50019748 0.50005593 0.50023111 0.50008959]\n",
      " [0.50015333 0.50008902 0.50022208 0.5001578 ]]\n",
      "\n",
      "it 35\n",
      "[[0.50018183 0.50004008 0.5002155  0.50007378]\n",
      " [0.50013641 0.50007189 0.50020521 0.50014071]]\n",
      "\n",
      "it 36\n",
      "[[0.50016789 0.50002597 0.5002016  0.50005971]\n",
      " [0.50012135 0.50005664 0.5001902  0.5001255 ]]\n",
      "\n",
      "it 37\n",
      "[[0.50015549 0.5000134  0.50018923 0.50004718]\n",
      " [0.50010794 0.50004306 0.50017682 0.50011196]]\n",
      "\n",
      "it 38\n",
      "[[0.50014444 0.50000221 0.50017821 0.50003602]\n",
      " [0.500096   0.50003097 0.50016492 0.5000999 ]]\n",
      "\n",
      "it 39\n",
      "[[0.50013461 0.49999226 0.50016841 0.50002609]\n",
      " [0.50008537 0.5000202  0.50015432 0.50008917]]\n",
      "\n",
      "it 40\n",
      "[[0.50012586 0.49998339 0.50015967 0.50001724]\n",
      " [0.50007591 0.50001062 0.50014488 0.50007961]]\n",
      "\n",
      "it 41\n",
      "[[0.50011806 0.4999755  0.5001519  0.50000937]\n",
      " [0.50006749 0.50000209 0.50013648 0.5000711 ]]\n",
      "\n",
      "it 42\n",
      "[[0.50011113 0.49996847 0.50014498 0.50000236]\n",
      " [0.50005999 0.4999945  0.500129   0.50006353]]\n",
      "\n",
      "it 43\n",
      "[[0.50010495 0.49996221 0.50013882 0.49999612]\n",
      " [0.50005331 0.49998773 0.50012234 0.50005678]]\n",
      "\n",
      "it 44\n",
      "[[0.50009945 0.49995664 0.50013334 0.49999056]\n",
      " [0.50004737 0.49998172 0.50011642 0.50005078]]\n",
      "\n",
      "it 45\n",
      "[[0.50009455 0.49995168 0.50012845 0.49998562]\n",
      " [0.50004208 0.49997636 0.50011114 0.50004544]]\n",
      "\n",
      "it 46\n",
      "[[0.5000902  0.49994727 0.50012411 0.49998121]\n",
      " [0.50003736 0.49997159 0.50010644 0.50004068]]\n",
      "\n",
      "it 47\n",
      "[[0.50008631 0.49994334 0.50012023 0.49997729]\n",
      " [0.50003317 0.49996734 0.50010226 0.50003644]]\n",
      "\n",
      "it 48\n",
      "[[0.50008286 0.49993984 0.50011679 0.4999738 ]\n",
      " [0.50002943 0.49996356 0.50009853 0.50003267]]\n",
      "\n",
      "it 49\n",
      "[[0.50007978 0.49993672 0.50011372 0.4999707 ]\n",
      " [0.50002611 0.49996019 0.50009521 0.50002931]]\n",
      "\n",
      "it 50\n",
      "[[0.50007705 0.49993395 0.50011099 0.49996793]\n",
      " [0.50002315 0.4999572  0.50009226 0.50002632]]\n",
      "\n",
      "it 51\n",
      "[[0.50007461 0.49993148 0.50010856 0.49996547]\n",
      " [0.50002051 0.49995453 0.50008963 0.50002366]]\n",
      "\n",
      "it 52\n",
      "[[0.50007244 0.49992929 0.50010639 0.49996327]\n",
      " [0.50001817 0.49995215 0.50008729 0.50002129]]\n",
      "\n",
      "it 53\n",
      "[[0.50007051 0.49992733 0.50010446 0.49996132]\n",
      " [0.50001608 0.49995004 0.50008521 0.50001919]]\n",
      "\n",
      "it 54\n",
      "[[0.50006879 0.49992559 0.50010275 0.49995958]\n",
      " [0.50001422 0.49994816 0.50008335 0.50001731]]\n",
      "\n",
      "it 55\n",
      "[[0.50006726 0.49992404 0.50010122 0.49995804]\n",
      " [0.50001256 0.49994648 0.5000817  0.50001564]]\n",
      "\n",
      "it 56\n",
      "[[0.50006589 0.49992266 0.50009986 0.49995666]\n",
      " [0.50001109 0.49994499 0.50008023 0.50001415]]\n",
      "\n",
      "it 57\n",
      "[[0.50006468 0.49992143 0.50009865 0.49995543]\n",
      " [0.50000978 0.49994366 0.50007892 0.50001282]]\n",
      "\n",
      "it 58\n",
      "[[0.5000636  0.49992033 0.50009757 0.49995434]\n",
      " [0.50000861 0.49994248 0.50007776 0.50001165]]\n",
      "\n",
      "it 59\n",
      "[[0.50006264 0.49991936 0.50009661 0.49995337]\n",
      " [0.50000757 0.49994143 0.50007672 0.5000106 ]]\n",
      "\n",
      "it 60\n",
      "[[0.50006178 0.49991849 0.50009575 0.4999525 ]\n",
      " [0.50000664 0.49994049 0.50007579 0.50000966]]\n",
      "\n",
      "it 61\n",
      "[[0.50006102 0.49991772 0.50009499 0.49995173]\n",
      " [0.50000582 0.49993966 0.50007497 0.50000883]]\n",
      "\n",
      "it 62\n",
      "[[0.50006034 0.49991703 0.50009431 0.49995104]\n",
      " [0.50000508 0.49993892 0.50007424 0.50000809]]\n",
      "\n",
      "it 63\n",
      "[[0.50005974 0.49991642 0.50009371 0.49995043]\n",
      " [0.50000443 0.49993826 0.50007358 0.50000743]]\n",
      "\n",
      "it 64\n",
      "[[0.5000592  0.49991588 0.50009317 0.49994989]\n",
      " [0.50000385 0.49993767 0.500073   0.50000684]]\n",
      "\n",
      "it 65\n",
      "[[0.50005872 0.49991539 0.5000927  0.49994941]\n",
      " [0.50000333 0.49993714 0.50007249 0.50000632]]\n",
      "\n",
      "it 66\n",
      "[[0.50005829 0.49991496 0.50009227 0.49994897]\n",
      " [0.50000287 0.49993668 0.50007202 0.50000585]]\n",
      "\n",
      "it 67\n",
      "[[0.50005791 0.49991458 0.50009189 0.49994859]\n",
      " [0.50000245 0.49993626 0.50007161 0.50000544]]\n",
      "\n",
      "it 68\n",
      "[[0.50005758 0.49991424 0.50009155 0.49994825]\n",
      " [0.50000209 0.49993589 0.50007125 0.50000507]]\n",
      "\n",
      "it 69\n",
      "[[0.50005728 0.49991393 0.50009125 0.49994794]\n",
      " [0.50000176 0.49993557 0.50007092 0.50000474]]\n",
      "\n",
      "it 70\n",
      "[[0.50005701 0.49991366 0.50009098 0.49994767]\n",
      " [0.50000147 0.49993527 0.50007063 0.50000445]]\n",
      "\n",
      "it 71\n",
      "[[0.50005677 0.49991342 0.50009074 0.49994743]\n",
      " [0.50000121 0.49993501 0.50007037 0.50000419]]\n",
      "\n",
      "it 72\n",
      "[[0.50005656 0.49991321 0.50009053 0.49994722]\n",
      " [0.50000098 0.49993478 0.50007014 0.50000396]]\n",
      "\n",
      "it 73\n",
      "[[0.50005637 0.49991302 0.50009034 0.49994702]\n",
      " [0.50000078 0.49993458 0.50006994 0.50000376]]\n",
      "\n",
      "it 74\n",
      "[[0.5000562  0.49991285 0.50009017 0.49994685]\n",
      " [0.5000006  0.49993439 0.50006976 0.50000357]]\n",
      "\n",
      "it 75\n",
      "[[0.50005605 0.49991269 0.50009002 0.4999467 ]\n",
      " [0.50000043 0.49993423 0.50006959 0.50000341]]\n",
      "\n",
      "it 76\n",
      "[[0.50005592 0.49991256 0.50008989 0.49994657]\n",
      " [0.50000029 0.49993409 0.50006945 0.50000326]]\n",
      "\n",
      "it 77\n",
      "[[0.5000558  0.49991244 0.50008977 0.49994645]\n",
      " [0.50000016 0.49993396 0.50006932 0.50000313]]\n",
      "\n",
      "it 78\n",
      "[[0.5000557  0.49991233 0.50008966 0.49994634]\n",
      " [0.50000005 0.49993384 0.5000692  0.50000302]]\n",
      "\n",
      "it 79\n",
      "[[0.5000556  0.49991224 0.50008957 0.49994624]\n",
      " [0.49999994 0.49993374 0.5000691  0.50000292]]\n",
      "\n",
      "it 80\n",
      "[[0.50005552 0.49991216 0.50008949 0.49994616]\n",
      " [0.49999985 0.49993365 0.50006901 0.50000283]]\n",
      "\n",
      "it 81\n",
      "[[0.50005544 0.49991208 0.50008941 0.49994608]\n",
      " [0.49999977 0.49993357 0.50006893 0.50000275]]\n",
      "\n",
      "it 82\n",
      "[[0.50005538 0.49991201 0.50008934 0.49994602]\n",
      " [0.4999997  0.4999335  0.50006886 0.50000267]]\n",
      "\n",
      "it 83\n",
      "[[0.50005532 0.49991196 0.50008928 0.49994596]\n",
      " [0.49999963 0.49993344 0.50006879 0.50000261]]\n",
      "\n",
      "it 84\n",
      "[[0.50005527 0.4999119  0.50008923 0.4999459 ]\n",
      " [0.49999958 0.49993338 0.50006873 0.50000255]]\n",
      "\n",
      "it 85\n",
      "[[0.50005522 0.49991186 0.50008918 0.49994585]\n",
      " [0.49999952 0.49993333 0.50006868 0.5000025 ]]\n",
      "\n",
      "it 86\n",
      "[[0.50005518 0.49991181 0.50008914 0.49994581]\n",
      " [0.49999948 0.49993328 0.50006864 0.50000246]]\n",
      "\n",
      "it 87\n",
      "[[0.50005514 0.49991178 0.5000891  0.49994577]\n",
      " [0.49999944 0.49993324 0.50006859 0.50000242]]\n",
      "\n",
      "it 88\n",
      "[[0.50005511 0.49991174 0.50008907 0.49994574]\n",
      " [0.4999994  0.49993321 0.50006856 0.50000238]]\n",
      "\n",
      "it 89\n",
      "[[0.50005508 0.49991172 0.50008904 0.49994571]\n",
      " [0.49999937 0.49993318 0.50006852 0.50000235]]\n",
      "\n",
      "it 90\n",
      "[[0.50005505 0.49991169 0.50008901 0.49994568]\n",
      " [0.49999934 0.49993315 0.5000685  0.50000232]]\n",
      "\n",
      "it 91\n",
      "[[0.50005503 0.49991167 0.50008899 0.49994566]\n",
      " [0.49999931 0.49993313 0.50006847 0.5000023 ]]\n",
      "\n",
      "it 92\n",
      "[[0.50005501 0.49991165 0.50008897 0.49994564]\n",
      " [0.49999929 0.4999331  0.50006845 0.50000228]]\n",
      "\n",
      "it 93\n",
      "[[0.50005499 0.49991163 0.50008895 0.49994562]\n",
      " [0.49999927 0.49993309 0.50006842 0.50000226]]\n",
      "\n",
      "it 94\n",
      "[[0.50005498 0.49991161 0.50008893 0.4999456 ]\n",
      " [0.49999925 0.49993307 0.50006841 0.50000224]]\n",
      "\n",
      "it 95\n",
      "[[0.50005496 0.4999116  0.50008891 0.49994559]\n",
      " [0.49999924 0.49993305 0.50006839 0.50000222]]\n",
      "\n",
      "it 96\n",
      "[[0.50005495 0.49991159 0.5000889  0.49994557]\n",
      " [0.49999922 0.49993304 0.50006837 0.50000221]]\n",
      "\n",
      "it 97\n",
      "[[0.50005494 0.49991157 0.50008889 0.49994556]\n",
      " [0.49999921 0.49993303 0.50006836 0.5000022 ]]\n",
      "\n",
      "it 98\n",
      "[[0.50005493 0.49991156 0.50008888 0.49994555]\n",
      " [0.4999992  0.49993302 0.50006835 0.50000219]]\n",
      "\n",
      "it 99\n",
      "[[0.50005492 0.49991156 0.50008887 0.49994554]\n",
      " [0.49999919 0.49993301 0.50006834 0.50000218]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2a8360c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "iterations = 100\n",
    "errors = []\n",
    "for i in range(0, iterations):\n",
    "    act = forward(X, WEIGHTS, 'sigmoid')\n",
    "    if i % 1 == 0:\n",
    "        print (\"it \" + str(i))\n",
    "        print(act[-1])\n",
    "    err = compute_error(act, np.transpose(Y))\n",
    "    #print (\"err at iter \" + str(i) + \": \" + str(err))\n",
    "    errors = errors + [err]\n",
    "    updates = backprop(X, act, Y, WEIGHTS, 'sigmoid', .25)\n",
    "    print \n",
    "    for j in range(0, len(WEIGHTS)):\n",
    "        WEIGHTS[j] = WEIGHTS[j] + updates[j]\n",
    "\n",
    "#print (\"errors: \" + str(errors))\n",
    "plt.plot(errors)\n",
    "\n",
    "plt.axis([0, len(errors), 0, 5])\n",
    "plt.ylabel('error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so this solves our toy example nicely. What about some real data? Let's try mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n"
     ]
    }
   ],
   "source": [
    "print('loading...')\n",
    "images = np.loadtxt('c:\\\\users\\\\anthaue\\\\onedrive\\\\documents\\\\school\\\\mnist\\\\t10k-images-idx3-ubyte.mat')\n",
    "labels = np.loadtxt('c:\\\\users\\\\anthaue\\\\onedrive\\\\documents\\\\school\\\\mnist\\\\t10k-labels-idx1-ubyte.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQX/AbBR6t76EwvkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29a80353048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 70000.0\n",
      "testacc: 0.11399999999999999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b7ef60a1a35a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWEIGHTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnonlinfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0merr\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcompute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWEIGHTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnonlinfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWEIGHTS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mWEIGHTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWEIGHTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-46008cd27215>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(X, A, Y, W, nl, rate)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_idx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mupcurr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mupcurr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQX/AbBR6t76EwvkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29a80353048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The mnist labels are a single dimension, but we'd rather\n",
    "#have them be a 10-dimensional array with 1 in the target dim\n",
    "#and zeros elsewhere else.\n",
    "import math\n",
    "def vectorize_targets(x):\n",
    "    ret = np.ones(([len(x), np.max(x) + 1]))\n",
    "    #Try setting to -1 instead of zero for tanh learner.\n",
    "    ret = ret * -1\n",
    "    print (ret)\n",
    "    for i in range(0, len(x)):\n",
    "        ret[i][x[i]] = 1\n",
    "    return ret\n",
    "#Need the bias ones on the training examples\n",
    "def prepend_ones_row(x):\n",
    "    return np.hstack((np.ones([len(x), 1]), x))\n",
    "    \n",
    "#We assume symmetric around zero.\n",
    "def init_random_matrix(rows, cols, magnitude):\n",
    "    ret = np.random.rand(rows, cols)\n",
    "    ret = ret - 0.5\n",
    "    ret = ret * (2 * magnitude)\n",
    "    return ret\n",
    "    \n",
    "def init_weights(X, Y, hiddenlen):\n",
    "    #magnitude = 0.05\n",
    "    (xrows, xcols) = X.shape\n",
    "    (yrows, ycols) = Y.shape\n",
    "    mag1 = 1 / math.sqrt(xcols)\n",
    "    x2hidden = init_random_matrix(hiddenlen, xcols, mag1)\n",
    "    mag2 = 1 / math.sqrt(hiddenlen)\n",
    "    hidden1hidden2 = init_random_matrix(hiddenlen, hiddenlen, mag2)\n",
    "    #hidden2hidden3 = init_random_matrix(hiddenlen, hiddenlen, magnitude)\n",
    "    #hidden3hidden4 = init_random_matrix(hiddenlen, hiddenlen, magnitude)\n",
    "    hidden2out = init_random_matrix(ycols, hiddenlen, mag2)\n",
    "    #return[x2hidden, hidden1hidden2, hidden2hidden3, hidden3hidden4, hidden4out]\n",
    "    return[x2hidden, hidden1hidden2, hidden2out]\n",
    "\n",
    "def normalize_inputs(normalizeMe, minscaled, maxscaled):\n",
    "    minunscaled = np.min(normalizeMe)\n",
    "    maxunscaled = np.max(normalizeMe)\n",
    "    ratio = (maxunscaled - minunscaled) / (maxscaled - minscaled)\n",
    "    print('minunscaled ' + str(minunscaled) + ', maxunscaled ' + str(maxunscaled) + ', ratio ' + str(ratio))\n",
    "    return minscaled + ((normalizeMe - minunscaled) / ratio)\n",
    "\n",
    "def split(samples, labels, trainpercent):\n",
    "    (rows, cols) = samples.shape\n",
    "    allRows = np.arange(rows)\n",
    "    np.random.shuffle(allRows)\n",
    "    cutoffRow = rows * trainpercent\n",
    "    trainIndices=allRows[0:cutoffRow]\n",
    "    testIndices=allRows[cutoffRow:]\n",
    "    trainSamples = samples[trainIndices]\n",
    "    trainLabels = labels[trainIndices]\n",
    "    testSamples = samples[testIndices]\n",
    "    testLabels = labels[testIndices]\n",
    "    return(trainSamples, trainLabels, testSamples, testLabels)\n",
    "    \n",
    "def accuracy(output, labels):\n",
    "    predmax = np.argmax(output, 1)\n",
    "    labmax = np.argmax(labels, 1)\n",
    "    diff = predmax - labmax\n",
    "    errors = np.count_nonzero(diff)\n",
    "    return 1.0 - (errors / len(output))\n",
    "    \n",
    "\n",
    "print('vectorizing...')\n",
    "veclabels = vectorize_targets(labels)\n",
    "print(veclabels)\n",
    "print('normalizing')\n",
    "normalized = normalize_inputs(images, -1, 1)\n",
    "print('biasing...')\n",
    "biased = prepend_ones_row(normalized)\n",
    "print(biased)\n",
    "\n",
    "(trainSamples, trainLabels, testSamples, testLabels) = split(biased, veclabels, 0.7)\n",
    "\n",
    "print('initializing weights...')\n",
    "WEIGHTS = init_weights(trainSamples, trainLabels, 200)\n",
    "\n",
    "plt.plot([], [])\n",
    "plt.show()\n",
    "from IPython import display\n",
    "\n",
    "iterations = 1000\n",
    "errors = []\n",
    "trainAccs = []\n",
    "testAccs = []\n",
    "mb_size = 10\n",
    "nonlinfunc = 'sigmoid'\n",
    "for i in range(0, iterations):\n",
    "    err=0\n",
    "    #Shuffle training cases.\n",
    "    order = np.arange(0, len(trainSamples))\n",
    "    np.random.shuffle(order)\n",
    "    trainSamples = trainSamples[order]\n",
    "    trainLabels = trainLabels[order]\n",
    "    for mbstart in range(0, len(trainSamples), mb_size):\n",
    "        mbend = min(len(trainSamples), mbstart + mb_size)\n",
    "        currX = trainSamples[mbstart:mbend,:]\n",
    "        currY = trainLabels[mbstart:mbend,:]\n",
    "        act = forward(currX, WEIGHTS, nonlinfunc)\n",
    "        err += compute_error(act, np.transpose(currY))\n",
    "        updates = backprop(currX, act, currY, WEIGHTS, nonlinfunc, 5.0)\n",
    "        for j in range(0, len(WEIGHTS)):\n",
    "            WEIGHTS[j] = WEIGHTS[j] + updates[j]\n",
    "    errors = errors + [err]\n",
    "    \n",
    "    trainOut = forward(trainSamples, WEIGHTS, nonlinfunc)\n",
    "    testOut = forward(testSamples, WEIGHTS, nonlinfunc)\n",
    "    trainAcc = accuracy(trainOut[-1].transpose(), trainLabels)\n",
    "    testAcc = accuracy(testOut[-1].transpose(), testLabels)\n",
    "    trainAccs = trainAccs + [trainAcc]\n",
    "    testAccs = testAccs + [testAcc]\n",
    "    \n",
    "\n",
    "#plt.plot(errors)\n",
    "    rng = np.arange(len(trainAccs))\n",
    "    #hl.set_xdata(rng)\n",
    "    #hl.set_ydata(trainAccs)\n",
    "    #hl.draw();\n",
    "    plt.clf()\n",
    "    plt.plot(rng, trainAccs, label='Train')\n",
    "    plt.plot(rng, testAccs, label='Test')\n",
    "    plt.legend(loc=2)\n",
    "    plt.axis([0, len(trainAccs), 0, 1.0])\n",
    "    plt.ylabel('training error')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    #plt.show()\n",
    "    print('error: ' + str(err))\n",
    "    print('testacc: ' + str(testAcc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
